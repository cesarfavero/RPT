{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RPT - Converter GGUF (CPU, sem GPU)\n\n**Pre-requisito:** Suba `bitnet_2b_pruned.tar.gz` na raiz do Google Drive.\n\nRuntime: **CPU** (nao precisa GPU)\n\nFixes criticos aplicados:\n- Bug #8: `weight_quant()` desabilitado (pesos ja ternarios)\n- Bug #10: architecture `bitnet` -> `bitnet-b1.58` (grafo computacional correto)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# CELL 1: MONTAR DRIVE + EXTRAIR TAR + INSTALAR DEPS\nimport os, json, shutil\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Extrair tar.gz do Drive\nTAR_FILE = '/content/drive/MyDrive/bitnet_2b_pruned.tar.gz'\nassert os.path.exists(TAR_FILE), 'ERRO: suba bitnet_2b_pruned.tar.gz na raiz do Google Drive!'\nprint(f'Tar encontrado: {os.path.getsize(TAR_FILE)/1e9:.1f} GB')\n\nprint('Extraindo...')\n!cd /content && tar xzf {TAR_FILE}\n\n# Renomear pra nome que o converter espera\nMODEL_DIR = '/content/BitNet-b1.58-2B-4T'\nif not os.path.exists(MODEL_DIR):\n    os.rename('/content/bitnet_2b_pruned', MODEL_DIR)\nprint(f'Modelo OK: {MODEL_DIR}')\n\n# Fix config.json\ncfg_path = os.path.join(MODEL_DIR, 'config.json')\nwith open(cfg_path) as f:\n    cfg = json.load(f)\nif cfg.get('architectures', [''])[0] == 'BitNetForCausalLM':\n    cfg['architectures'] = ['BitnetForCausalLM']\n    with open(cfg_path, 'w') as f:\n        json.dump(cfg, f, indent=2)\n    print('Fix: BitNetForCausalLM -> BitnetForCausalLM')\n\n# Fix tokenizer_config.json\ntok_path = os.path.join(MODEL_DIR, 'tokenizer_config.json')\nwith open(tok_path) as f:\n    tok = json.load(f)\nif tok.get('tokenizer_class') == 'TokenizersBackend':\n    tok['tokenizer_class'] = 'PreTrainedTokenizerFast'\n    with open(tok_path, 'w') as f:\n        json.dump(tok, f, indent=2)\n    print('Fix: TokenizersBackend -> PreTrainedTokenizerFast')\n\n# Instalar clang\nprint('Instalando clang...')\n!sudo apt-get update -qq && sudo apt-get install -y -qq clang lld 2>&1 | tail -1\n\n# Clonar BitNet\nif not os.path.exists('BitNet'):\n    !git clone --recursive https://github.com/microsoft/BitNet.git\nelse:\n    !cd BitNet && git submodule update --init --recursive 2>&1 | tail -1\n\n# FIX 10: Architecture bitnet -> bitnet-b1.58 (ANTES do pip install!)\nprint('Fix architecture no gguf-py...')\nconstants_file = 'BitNet/3rdparty/llama.cpp/gguf-py/gguf/constants.py'\nwith open(constants_file) as f:\n    code = f.read()\nif 'MODEL_ARCH.BITNET:         \"bitnet\",' in code:\n    code = code.replace(\n        'MODEL_ARCH.BITNET:         \"bitnet\",',\n        'MODEL_ARCH.BITNET:         \"bitnet-b1.58\",'\n    )\n    with open(constants_file, 'w') as f:\n        f.write(code)\n    print('Fix: architecture bitnet -> bitnet-b1.58')\nelse:\n    print('Fix architecture ja aplicado')\n\n# Instalar deps (force-reinstall gguf-py APOS o patch!)\n!pip install -q -r BitNet/requirements.txt\n!pip install -q --force-reinstall --no-deps BitNet/3rdparty/llama.cpp/gguf-py\n\nprint('=== SETUP OK ===')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CELL 2: GERAR KERNELS + COMPILAR\n",
    "import os\n",
    "\n",
    "print('[1/3] Gerando kernels...')\n",
    "!cd BitNet && python3 utils/codegen_tl2.py --model bitnet_b1_58-3B --BM 160,320,320 --BK 96,96,96 --bm 32,32,32\n",
    "\n",
    "# Fix const correctness\n",
    "print('[2/3] Fix compilacao...')\n",
    "mad_file = 'BitNet/src/ggml-bitnet-mad.cpp'\n",
    "if os.path.exists(mad_file):\n",
    "    with open(mad_file) as f:\n",
    "        code = f.read()\n",
    "    code = code.replace('int8_t * y_col = y + col * by;', 'const int8_t * y_col = y + col * by;')\n",
    "    with open(mad_file, 'w') as f:\n",
    "        f.write(code)\n",
    "\n",
    "print('[3/3] Compilando...')\n",
    "!cd BitNet && cmake -B build -DBITNET_X86_TL2=OFF -DCMAKE_C_COMPILER=clang -DCMAKE_CXX_COMPILER=clang++ 2>&1 | tail -3\n",
    "!cd BitNet && cmake --build build --config Release -j$(nproc) 2>&1 | tail -3\n",
    "\n",
    "assert os.path.exists('BitNet/build/bin/llama-quantize'), 'ERRO: compilacao falhou!'\n",
    "print('Compilacao OK!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# CELL 3: FIX CONVERTER + CONVERTER GGUF\nimport os\n\nMODEL_DIR = '/content/BitNet-b1.58-2B-4T'\n\n# Fix vocab fallback no converter\nprint('[1/4] Aplicando fix no converter...')\nconv_file = 'BitNet/utils/convert-hf-to-gguf-bitnet.py'\nwith open(conv_file) as f:\n    code = f.read()\n\nbitnet_pos = code.rfind('class BitnetModel')\nif bitnet_pos > 0:\n    old_pos = code.find('self._set_vocab_sentencepiece()', bitnet_pos)\n    if old_pos > 0:\n        method_start = code.rfind('def set_vocab(self):', 0, old_pos)\n        method_end = old_pos + len('self._set_vocab_sentencepiece()')\n        code = code[:method_start] + '''def set_vocab(self):\n        try:\n            self._set_vocab_sentencepiece()\n        except FileNotFoundError:\n            try:\n                self._set_vocab_llama_hf()\n            except (FileNotFoundError, TypeError):\n                self._set_vocab_gpt2()''' + code[method_end:]\n        with open(conv_file, 'w') as f:\n            f.write(code)\n        print('Fix aplicado')\n\n# Fix weight_quant (BUG 8): converter re-quantiza pesos ja ternarios com escala errada\nprint('[2/4] Desabilitando weight_quant (pesos ja ternarios)...')\nwith open(conv_file) as f:\n    code = f.read()\nif 'data_torch = self.weight_quant(data_torch)' in code:\n    code = code.replace(\n        'data_torch = self.weight_quant(data_torch)',\n        'pass  # RPT fix: pesos ja ternarios, skip re-quantizacao'\n    )\n    with open(conv_file, 'w') as f:\n        f.write(code)\n    print('Fix: weight_quant desabilitado')\n\n# Converter HF -> f32 GGUF\nprint('[3/4] Convertendo para GGUF f32...')\n!cd BitNet && python3 utils/convert-hf-to-gguf-bitnet.py {MODEL_DIR} --outtype f32\n\nf32_gguf = os.path.join(MODEL_DIR, 'ggml-model-f32.gguf')\nassert os.path.exists(f32_gguf), 'ERRO: conversao falhou!'\nprint(f'f32 OK: {os.path.getsize(f32_gguf)/1e9:.1f} GB')\n\n# Quantizar f32 -> i2_s\nprint('[4/4] Quantizando para i2_s...')\ni2s_gguf = os.path.join(MODEL_DIR, 'ggml-model-i2_s.gguf')\n!BitNet/build/bin/llama-quantize {f32_gguf} {i2s_gguf} I2_S 1\n\nassert os.path.exists(i2s_gguf), 'ERRO: quantizacao falhou!'\nprint(f'\\nGGUF i2_s: {os.path.getsize(i2s_gguf)/1e6:.0f} MB')\n\nos.remove(f32_gguf)\nprint('CONVERSAO OK!')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CELL 4: TESTAR INFERENCIA\n",
    "import os\n",
    "i2s_gguf = '/content/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf'\n",
    "!cd BitNet && python3 run_inference.py -m {i2s_gguf} -p \"The capital of France is\" -n 50 -t 4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# CELL 5: SALVAR GGUF NO DRIVE + DOWNLOAD\nimport os, shutil\ni2s_gguf = '/content/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf'\n\n# Copiar pro Drive\ndrive_dest = '/content/drive/MyDrive/bitnet_2b_pruned_gguf/'\nos.makedirs(drive_dest, exist_ok=True)\nshutil.copy2(i2s_gguf, drive_dest)\nprint(f'GGUF salvo no Drive: {drive_dest}')\nprint(f'Tamanho: {os.path.getsize(os.path.join(drive_dest, \"ggml-model-i2_s.gguf\"))/1e6:.0f} MB')\n\n# Download direto\nfrom google.colab import files\nfiles.download(i2s_gguf)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}