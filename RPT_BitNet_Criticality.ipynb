{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RPT - Validacao de Criticalidade Auto-Organizada no BitNet 2B\n",
        "#\n",
        "# Criticalidade Auto-Organizada (SOC) preve que redes neurais otimas operam\n",
        "# \"na borda do caos\" com branching ratio ~1.0.\n",
        "#\n",
        "# Medimos:\n",
        "# 1. Branching ratio: ||output|| / ||input|| por camada (~1.0 = critico)\n",
        "# 2. Perturbation test: ruido no embedding cresce, diminui ou se mantem?\n",
        "# 3. Lyapunov exponent: taxa de crescimento de perturbacoes (~0 = critico)\n",
        "#\n",
        "# So medicao, sem treino. Forward hooks capturam ativacoes.\n",
        "#\n",
        "# IMPORTANTE: Rode Cell 1, REINICIE o runtime, rode Cell 1 de novo e continue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 1: SETUP\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q git+https://github.com/huggingface/transformers.git accelerate datasets\n",
        "\n",
        "import torch\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import transformers\n",
        "\n",
        "print('Transformers:', transformers.__version__)\n",
        "print('Torch:', torch.__version__)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n",
        "if device.type == 'cuda':\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "    mem = torch.cuda.get_device_properties(0).total_memory\n",
        "    print('VRAM: {:.1f} GB'.format(mem / 1e9))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 2: CARREGAR MODELO\n",
        "MODEL_ID = 'microsoft/bitnet-b1.58-2B-4T-bf16'\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "print('Carregando tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print('Carregando modelo BitNet 2B...')\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    dtype=torch.bfloat16,\n",
        "    device_map='auto'\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print('Parametros: {:,.0f} ({:.1f}B)'.format(n_params, n_params / 1e9))\n",
        "\n",
        "num_layers = model.config.num_hidden_layers\n",
        "hidden_size = model.config.hidden_size\n",
        "print('Camadas: {}'.format(num_layers))\n",
        "print('Hidden size: {}'.format(hidden_size))\n",
        "\n",
        "# Detectar nomes das camadas\n",
        "_modules_dict = dict(model.named_modules())\n",
        "layer_names = []\n",
        "for i in range(num_layers):\n",
        "    for pattern in ['model.layers.{}', 'transformer.h.{}', 'gpt_neox.layers.{}']:\n",
        "        name = pattern.format(i)\n",
        "        if name in _modules_dict:\n",
        "            layer_names.append(name)\n",
        "            break\n",
        "\n",
        "print('Blocos transformer: {}'.format(len(layer_names)))\n",
        "\n",
        "# Detectar embedding layer\n",
        "embed_module = None\n",
        "for embed_name in ['model.model.embed_tokens', 'model.embed_tokens', 'transformer.wte', 'gpt_neox.embed_in']:\n",
        "    if embed_name in _modules_dict:\n",
        "        embed_module = _modules_dict[embed_name]\n",
        "        print('Embedding: {}'.format(embed_name))\n",
        "        break\n",
        "\n",
        "if embed_module is None:\n",
        "    for name, mod in _modules_dict.items():\n",
        "        if isinstance(mod, torch.nn.Embedding) and 'embed' in name.lower():\n",
        "            embed_module = mod\n",
        "            print('Embedding (fallback): {}'.format(name))\n",
        "            break\n",
        "\n",
        "if embed_module is None:\n",
        "    print('AVISO: Embedding nao encontrado! Perturbation test nao vai funcionar.')\n",
        "\n",
        "\n",
        "def _get_module(name):\n",
        "    return _modules_dict.get(name)\n",
        "\n",
        "\n",
        "if device.type == 'cuda':\n",
        "    print('VRAM: {:.1f} GB'.format(torch.cuda.memory_allocated() / 1e9))\n",
        "print('Pronto!')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 3: DATASET + FUNCOES BASE\n",
        "from datasets import load_dataset\n",
        "\n",
        "print('Carregando WikiText-2 validacao...')\n",
        "val_dataset = load_dataset('wikitext', 'wikitext-2-raw-v1', split='validation')\n",
        "\n",
        "SEQ_LEN = 128\n",
        "val_ids = []\n",
        "for example in val_dataset:\n",
        "    text = example['text'].strip()\n",
        "    if len(text) < 20:\n",
        "        continue\n",
        "    val_ids.extend(tokenizer.encode(text, add_special_tokens=False))\n",
        "\n",
        "val_chunks = []\n",
        "for i in range(0, len(val_ids) - SEQ_LEN, SEQ_LEN):\n",
        "    val_chunks.append(torch.tensor(val_ids[i:i + SEQ_LEN], dtype=torch.long))\n",
        "\n",
        "print('Val chunks: {:,}'.format(len(val_chunks)))\n",
        "\n",
        "sample_texts = []\n",
        "for example in val_dataset:\n",
        "    text = example['text'].strip()\n",
        "    if len(text) > 100:\n",
        "        sample_texts.append(text[:500])\n",
        "    if len(sample_texts) >= 20:\n",
        "        break\n",
        "print('Textos para analise: {}'.format(len(sample_texts)))\n",
        "\n",
        "\n",
        "def compute_ppl(model, val_chunks, max_batches=50):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_tokens = 0\n",
        "    for chunk in val_chunks[:max_batches]:\n",
        "        input_ids = chunk.unsqueeze(0).to(model.device if hasattr(model, 'device') else 'cuda')\n",
        "        with torch.no_grad():\n",
        "            out = model(input_ids=input_ids, labels=input_ids)\n",
        "        total_loss += out.loss.item() * (chunk.shape[0] - 1)\n",
        "        total_tokens += chunk.shape[0] - 1\n",
        "    return torch.exp(torch.tensor(total_loss / total_tokens)).item()\n",
        "\n",
        "\n",
        "print('Funcoes definidas.')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 4: CLASSES DE ANALISE\n",
        "\n",
        "class ActivationAnalyzer:\n",
        "    \"\"\"Captura normas e ratios de ativacoes em cada camada.\n",
        "    \n",
        "    Branching ratio = ||output|| / ||input|| por camada.\n",
        "    Na criticalidade: ratio ~1.0 (ativacoes nem crescem nem diminuem).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.hooks = []\n",
        "        self.data = {}\n",
        "    \n",
        "    def register(self, layer_names):\n",
        "        for name in layer_names:\n",
        "            module = _get_module(name)\n",
        "            if module is None:\n",
        "                continue\n",
        "            self.data[name] = []\n",
        "            handle = module.register_forward_hook(self._make_hook(name))\n",
        "            self.hooks.append(handle)\n",
        "        print('ActivationAnalyzer: {} hooks'.format(len(self.hooks)))\n",
        "    \n",
        "    def _make_hook(self, name):\n",
        "        data_list = self.data[name]\n",
        "        def hook_fn(module, input, output):\n",
        "            x_in = input[0] if isinstance(input, tuple) else input\n",
        "            x_out = output[0] if isinstance(output, tuple) else output\n",
        "            \n",
        "            if not isinstance(x_in, torch.Tensor) or not isinstance(x_out, torch.Tensor):\n",
        "                return\n",
        "            if x_in.shape != x_out.shape:\n",
        "                return\n",
        "            \n",
        "            x_in_f = x_in.detach().float()\n",
        "            x_out_f = x_out.detach().float()\n",
        "            correction = x_out_f - x_in_f\n",
        "            \n",
        "            in_norm = x_in_f.norm(dim=-1).mean().item()\n",
        "            out_norm = x_out_f.norm(dim=-1).mean().item()\n",
        "            corr_norm = correction.norm(dim=-1).mean().item()\n",
        "            \n",
        "            data_list.append({\n",
        "                'in_norm': in_norm,\n",
        "                'out_norm': out_norm,\n",
        "                'corr_norm': corr_norm,\n",
        "                'branching_ratio': out_norm / (in_norm + 1e-8),\n",
        "                'correction_ratio': corr_norm / (in_norm + 1e-8),\n",
        "            })\n",
        "        return hook_fn\n",
        "    \n",
        "    def get_summary(self):\n",
        "        summary = {}\n",
        "        for name, data_list in self.data.items():\n",
        "            if not data_list:\n",
        "                continue\n",
        "            avg = {}\n",
        "            for key in data_list[0]:\n",
        "                vals = [d[key] for d in data_list]\n",
        "                avg[key] = sum(vals) / len(vals)\n",
        "            avg['n_samples'] = len(data_list)\n",
        "            summary[name] = avg\n",
        "        return summary\n",
        "    \n",
        "    def remove(self):\n",
        "        for h in self.hooks:\n",
        "            h.remove()\n",
        "        self.hooks.clear()\n",
        "        self.data.clear()\n",
        "\n",
        "\n",
        "class PerturbationTest:\n",
        "    \"\"\"Mede como perturbacoes propagam pelas camadas.\n",
        "    \n",
        "    Adiciona ruido gaussiano ao embedding e mede delta relativo em cada camada.\n",
        "    Na criticalidade: delta nao cresce nem diminui (Lyapunov ~0).\n",
        "    Subcritico: delta diminui (Lyapunov < 0).\n",
        "    Supercritico: delta cresce (Lyapunov > 0).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.layer_hooks = []\n",
        "        self.embed_hook = None\n",
        "        self.clean_outputs = {}\n",
        "        self.deltas = {}\n",
        "        self.mode = 'clean'\n",
        "        self.epsilon = 0.01\n",
        "    \n",
        "    def register(self, layer_names, epsilon=0.01):\n",
        "        self.epsilon = epsilon\n",
        "        self.deltas = {name: [] for name in layer_names}\n",
        "        \n",
        "        for name in layer_names:\n",
        "            module = _get_module(name)\n",
        "            if module is None:\n",
        "                continue\n",
        "            handle = module.register_forward_hook(self._make_hook(name))\n",
        "            self.layer_hooks.append(handle)\n",
        "        print('PerturbationTest: {} hooks, eps={}'.format(len(self.layer_hooks), epsilon))\n",
        "    \n",
        "    def _make_hook(self, name):\n",
        "        test = self\n",
        "        def hook_fn(module, input, output):\n",
        "            x_out = output[0] if isinstance(output, tuple) else output\n",
        "            if not isinstance(x_out, torch.Tensor):\n",
        "                return\n",
        "            \n",
        "            if test.mode == 'clean':\n",
        "                test.clean_outputs[name] = x_out.detach().clone()\n",
        "            elif test.mode == 'perturbed':\n",
        "                clean = test.clean_outputs.get(name)\n",
        "                if clean is not None and clean.shape == x_out.shape:\n",
        "                    delta = (x_out.detach().float() - clean.float()).norm().item()\n",
        "                    clean_norm = clean.float().norm().item()\n",
        "                    test.deltas[name].append(delta / (clean_norm + 1e-8))\n",
        "        return hook_fn\n",
        "    \n",
        "    def _perturb_embed(self, module, input, output):\n",
        "        noise = torch.randn_like(output) * self.epsilon\n",
        "        return output + noise\n",
        "    \n",
        "    def run(self, model, tokenizer, embed_module, texts):\n",
        "        for i, text in enumerate(texts):\n",
        "            inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=256)\n",
        "            inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "            \n",
        "            # Pass 1: clean\n",
        "            self.mode = 'clean'\n",
        "            with torch.no_grad():\n",
        "                _ = model(**inputs)\n",
        "            \n",
        "            # Pass 2: perturbed\n",
        "            self.mode = 'perturbed'\n",
        "            self.embed_hook = embed_module.register_forward_hook(self._perturb_embed)\n",
        "            with torch.no_grad():\n",
        "                _ = model(**inputs)\n",
        "            self.embed_hook.remove()\n",
        "            self.embed_hook = None\n",
        "            \n",
        "            self.clean_outputs.clear()\n",
        "            \n",
        "            if (i + 1) % 5 == 0:\n",
        "                print('  Perturbation: {}/{}'.format(i + 1, len(texts)))\n",
        "    \n",
        "    def get_results(self):\n",
        "        results = {}\n",
        "        for name, delta_list in self.deltas.items():\n",
        "            if delta_list:\n",
        "                results[name] = sum(delta_list) / len(delta_list)\n",
        "        return results\n",
        "    \n",
        "    def remove(self):\n",
        "        for h in self.layer_hooks:\n",
        "            h.remove()\n",
        "        self.layer_hooks.clear()\n",
        "        if self.embed_hook:\n",
        "            self.embed_hook.remove()\n",
        "        self.clean_outputs.clear()\n",
        "        self.deltas.clear()\n",
        "\n",
        "\n",
        "# Teste rapido\n",
        "print('Testando hooks...')\n",
        "test_analyzer = ActivationAnalyzer()\n",
        "test_analyzer.register(layer_names)\n",
        "\n",
        "test_input = tokenizer('Hello world', return_tensors='pt')\n",
        "test_input = {k: v.to('cuda') for k, v in test_input.items()}\n",
        "with torch.no_grad():\n",
        "    _ = model(**test_input)\n",
        "\n",
        "test_summary = test_analyzer.get_summary()\n",
        "test_analyzer.remove()\n",
        "\n",
        "if test_summary:\n",
        "    first = list(test_summary.values())[0]\n",
        "    print('  OK! Branching ratio layer 0: {:.4f}'.format(first['branching_ratio']))\n",
        "else:\n",
        "    print('  ERRO: Hooks nao capturaram nada!')\n",
        "\n",
        "print('Classes: ActivationAnalyzer, PerturbationTest')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 5: MEDIR BRANCHING RATIOS\n",
        "\n",
        "print('=== BRANCHING RATIO: PROPAGACAO DE ATIVACOES ===')\n",
        "print('Medindo em {} textos, {} camadas...'.format(len(sample_texts), len(layer_names)))\n",
        "print()\n",
        "\n",
        "ppl_baseline = compute_ppl(model, val_chunks)\n",
        "print('PPL baseline: {:.2f}'.format(ppl_baseline))\n",
        "print()\n",
        "\n",
        "analyzer = ActivationAnalyzer()\n",
        "analyzer.register(layer_names)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, text in enumerate(sample_texts):\n",
        "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=256)\n",
        "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "        _ = model(**inputs)\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print('  Processados {}/{}'.format(i + 1, len(sample_texts)))\n",
        "\n",
        "summary = analyzer.get_summary()\n",
        "analyzer.remove()\n",
        "\n",
        "print()\n",
        "print('{:<10} {:>10} {:>10} {:>10} {:>12} {:>12}'.format(\n",
        "    'Camada', '||input||', '||output||', '||corr||', 'Branch.Ratio', 'Corr.Ratio'))\n",
        "print('-' * 75)\n",
        "\n",
        "branching_ratios = []\n",
        "correction_ratios = []\n",
        "\n",
        "for name in layer_names:\n",
        "    if name not in summary:\n",
        "        continue\n",
        "    s = summary[name]\n",
        "    idx = int(name.split('.')[-1])\n",
        "    br = s['branching_ratio']\n",
        "    cr = s['correction_ratio']\n",
        "    branching_ratios.append(br)\n",
        "    correction_ratios.append(cr)\n",
        "    \n",
        "    print('{:<10} {:>10.1f} {:>10.1f} {:>10.1f} {:>12.4f} {:>12.4f}'.format(\n",
        "        'Layer {}'.format(idx),\n",
        "        s['in_norm'], s['out_norm'], s['corr_norm'],\n",
        "        br, cr))\n",
        "\n",
        "print()\n",
        "avg_br = sum(branching_ratios) / len(branching_ratios)\n",
        "std_br = (sum((x - avg_br)**2 for x in branching_ratios) / len(branching_ratios)) ** 0.5\n",
        "\n",
        "print('=== BRANCHING RATIO ===')\n",
        "print('Media: {:.4f} (desvio: {:.4f})'.format(avg_br, std_br))\n",
        "print('Min:   {:.4f} (Layer {})'.format(min(branching_ratios), branching_ratios.index(min(branching_ratios))))\n",
        "print('Max:   {:.4f} (Layer {})'.format(max(branching_ratios), branching_ratios.index(max(branching_ratios))))\n",
        "\n",
        "if abs(avg_br - 1.0) < 0.1:\n",
        "    print('-> CRITICO: branching ratio ~1.0! Modelo opera na borda do caos.')\n",
        "elif avg_br < 1.0:\n",
        "    print('-> SUBCRITICO: ativacoes diminuem camada a camada.')\n",
        "else:\n",
        "    print('-> SUPERCRITICO: ativacoes crescem camada a camada.')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 6: TESTE DE PERTURBACAO\n",
        "\n",
        "print('=== PERTURBATION TEST ===')\n",
        "print('Adicionando ruido gaussiano (eps=0.01) ao embedding')\n",
        "print('Medindo propagacao do ruido camada a camada...')\n",
        "print()\n",
        "\n",
        "if embed_module is None:\n",
        "    print('ERRO: Embedding nao encontrado. Pulando perturbation test.')\n",
        "    perturb_results = {}\n",
        "    lyapunov = None\n",
        "    amplification = None\n",
        "else:\n",
        "    perturb = PerturbationTest()\n",
        "    perturb.register(layer_names, epsilon=0.01)\n",
        "    perturb.run(model, tokenizer, embed_module, sample_texts)\n",
        "    perturb_results = perturb.get_results()\n",
        "    perturb.remove()\n",
        "    \n",
        "    print()\n",
        "    print('{:<10} {:>15} {:>15}'.format('Camada', 'Delta Relativo', 'log(delta)'))\n",
        "    print('-' * 45)\n",
        "    \n",
        "    deltas = []\n",
        "    for name in layer_names:\n",
        "        if name not in perturb_results:\n",
        "            continue\n",
        "        idx = int(name.split('.')[-1])\n",
        "        d = perturb_results[name]\n",
        "        deltas.append(d)\n",
        "        log_d = math.log(d) if d > 0 else float('-inf')\n",
        "        print('{:<10} {:>15.6f} {:>15.4f}'.format('Layer {}'.format(idx), d, log_d))\n",
        "    \n",
        "    print()\n",
        "    if len(deltas) >= 2:\n",
        "        # Lyapunov exponent: taxa media de crescimento por camada\n",
        "        lyapunov = (math.log(deltas[-1] + 1e-12) - math.log(deltas[0] + 1e-12)) / (len(deltas) - 1)\n",
        "        amplification = deltas[-1] / (deltas[0] + 1e-12)\n",
        "        \n",
        "        print('=== LYAPUNOV EXPONENT ===')\n",
        "        print('Lambda: {:.4f}'.format(lyapunov))\n",
        "        print('Amplificacao total: {:.2f}x (layer 0 -> layer {})'.format(\n",
        "            amplification, len(deltas) - 1))\n",
        "        \n",
        "        if abs(lyapunov) < 0.05:\n",
        "            print('-> CRITICO: perturbacoes se propagam estavelmente (lambda ~0)')\n",
        "        elif lyapunov < 0:\n",
        "            print('-> SUBCRITICO: perturbacoes diminuem (lambda < 0)')\n",
        "        else:\n",
        "            print('-> SUPERCRITICO: perturbacoes crescem (lambda > 0)')\n",
        "    else:\n",
        "        lyapunov = None\n",
        "        amplification = None\n",
        "        print('Poucos dados para calcular Lyapunov.')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 7: RESULTADOS + CONCLUSAO\n",
        "\n",
        "print('=' * 80)\n",
        "print('RESULTADOS: CRITICALIDADE AUTO-ORGANIZADA NO BITNET 2B')\n",
        "print('=' * 80)\n",
        "print()\n",
        "\n",
        "print('--- 1. BRANCHING RATIO ---')\n",
        "print('Media: {:.4f}'.format(avg_br))\n",
        "print('Desvio: {:.4f}'.format(std_br))\n",
        "print('Faixa: {:.4f} - {:.4f}'.format(min(branching_ratios), max(branching_ratios)))\n",
        "\n",
        "near_one = sum(1 for br in branching_ratios if 0.95 <= br <= 1.05)\n",
        "print('Camadas com ratio 0.95-1.05: {}/{}'.format(near_one, len(branching_ratios)))\n",
        "print()\n",
        "\n",
        "if perturb_results and lyapunov is not None:\n",
        "    print('--- 2. PERTURBATION TEST ---')\n",
        "    print('Epsilon: 0.01')\n",
        "    print('Lyapunov exponent: {:.4f}'.format(lyapunov))\n",
        "    print('Amplificacao: {:.2f}x'.format(amplification))\n",
        "    print()\n",
        "\n",
        "print('--- CONCLUSAO ---')\n",
        "is_critical_br = abs(avg_br - 1.0) < 0.1\n",
        "is_critical_lyap = lyapunov is not None and abs(lyapunov) < 0.05\n",
        "\n",
        "if is_critical_br and is_critical_lyap:\n",
        "    print('SOC VALIDADO: BitNet 2B opera na criticalidade!')\n",
        "    print('  - Branching ratio ~1.0 ({:.4f})'.format(avg_br))\n",
        "    print('  - Perturbacoes estaveis (lambda={:.4f})'.format(lyapunov))\n",
        "    print('  - Modelo esta na borda do caos como previsto pela teoria RPT')\n",
        "elif is_critical_br:\n",
        "    print('SOC PARCIAL: Branching ratio ~1.0, mas perturbacoes nao estaveis')\n",
        "    print('  - Branching ratio: {:.4f}'.format(avg_br))\n",
        "    if lyapunov is not None:\n",
        "        print('  - Lyapunov: {:.4f} (deveria ser ~0)'.format(lyapunov))\n",
        "elif is_critical_lyap:\n",
        "    print('SOC PARCIAL: Perturbacoes estaveis, mas branching ratio != 1.0')\n",
        "    print('  - Branching ratio: {:.4f} (deveria ser ~1.0)'.format(avg_br))\n",
        "    print('  - Lyapunov: {:.4f}'.format(lyapunov))\n",
        "else:\n",
        "    regime = 'SUBCRITICO' if avg_br < 1.0 else 'SUPERCRITICO'\n",
        "    print('SOC NAO CONFIRMADO: modelo e {}'.format(regime))\n",
        "    print('  - Branching ratio: {:.4f}'.format(avg_br))\n",
        "    if lyapunov is not None:\n",
        "        print('  - Lyapunov: {:.4f}'.format(lyapunov))\n",
        "\n",
        "print()\n",
        "print('=== COMPARACAO COM RESULTADOS ANTERIORES ===')\n",
        "print('Esparsidade de pesos 10%: PPL melhora -26% (VALIDADO)')\n",
        "print('Predictive coding: ativacoes nao sao redundantes (NAO CONFIRMADO)')\n",
        "print('Criticalidade: branching ratio = {:.4f}'.format(avg_br))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 8: SALVAR RESULTADOS\n",
        "\n",
        "report = {\n",
        "    'model': MODEL_ID,\n",
        "    'date': '2026-02-06',\n",
        "    'experiment': 'self_organized_criticality_bitnet_2b',\n",
        "    'config': {\n",
        "        'gpu': torch.cuda.get_device_name(0) if device.type == 'cuda' else 'cpu',\n",
        "        'num_layers': len(layer_names),\n",
        "        'seq_len': SEQ_LEN,\n",
        "        'num_sample_texts': len(sample_texts),\n",
        "        'perturbation_epsilon': 0.01,\n",
        "        'dataset': 'wikitext-2',\n",
        "    },\n",
        "    'baseline_ppl': ppl_baseline,\n",
        "    'branching_ratios': {},\n",
        "    'perturbation_deltas': {},\n",
        "    'summary': {\n",
        "        'avg_branching_ratio': avg_br,\n",
        "        'std_branching_ratio': std_br,\n",
        "        'min_branching_ratio': min(branching_ratios),\n",
        "        'max_branching_ratio': max(branching_ratios),\n",
        "        'layers_near_critical': near_one,\n",
        "    },\n",
        "}\n",
        "\n",
        "if lyapunov is not None:\n",
        "    report['summary']['lyapunov_exponent'] = lyapunov\n",
        "    report['summary']['total_amplification'] = amplification\n",
        "\n",
        "for name in layer_names:\n",
        "    if name in summary:\n",
        "        report['branching_ratios'][name] = summary[name]\n",
        "    if name in perturb_results:\n",
        "        report['perturbation_deltas'][name] = perturb_results[name]\n",
        "\n",
        "filename = 'criticality_bitnet2b_results.json'\n",
        "with open(filename, 'w') as f:\n",
        "    json.dump(report, f, indent=2)\n",
        "\n",
        "print('Salvo em {}'.format(filename))\n",
        "print()\n",
        "print('=== RESUMO FINAL ===')\n",
        "print('Branching ratio medio: {:.4f}'.format(avg_br))\n",
        "if lyapunov is not None:\n",
        "    print('Lyapunov exponent: {:.4f}'.format(lyapunov))\n",
        "print('PPL baseline: {:.2f}'.format(ppl_baseline))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CELL 9: DOWNLOAD RESULTADOS\n",
        "import os\n",
        "\n",
        "filename = 'criticality_bitnet2b_results.json'\n",
        "filepath = os.path.abspath(filename)\n",
        "print('Arquivo salvo em: {}'.format(filepath))\n",
        "print('Tamanho: {:.1f} KB'.format(os.path.getsize(filepath) / 1024))\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(filename)\n",
        "    print('Download Colab iniciado.')\n",
        "except ImportError:\n",
        "    print('Nao esta no Colab. Copie o arquivo manualmente do caminho acima.')"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}